
# 2020's Best Practice pillars for the Java ecosystem
#### (title continued...) relative to Java from '00s, from tech manager's POV, with examples. Plus a few bad practices
by Vic Cekvenich

Summary: The listed difference amount to a difference in kind, not a difference in degree. 

### Background

I am Vic Cekvenich, my claim to fame is writing the first book on Java Struts, a predecessor to Spring Boot. I have been looking at Apache Spark, Akka, etc. and I think we can do better, specially as polyglot. There are few ideas we can leverage from NodeJS's Express library. 
And by better I might easier and faster. So lets review the 2020's Best Practice pillars for the Java ecosystem! 

## #1. Scala, Kotlin, Groovy
SDKMan, Scala, and Java 11 are incremental improvements for the 2020's Java ecosystem.

Kotlin is JVM default used for Google's Andorid platform. Scala is popular for Data Science. And Groovy is dynamic, like NodeJS and Python.
All 3 are more concise than Java for writing applications, utilities, etc. Of the 3 Scala seems easiest to adopt, you can for example go online and paste Java code and it will be converted to Scala. But when writing a library, it is better to write it in Java, so it can be used by others on the JVM platform. 

In 2020's we install Java 11 LTS via SDKMan, and run simply the app via:

```
	java -jar app1.jar
``` 

Oh, an why be JVM based? Because JVM is better then C++, the closest alternative. (One example of why C++ is bad is that trillion dollar F35 plane is a failure, and it was written in C++)


## #2: DB in RAM Memory

DB's using RAM is a new and revolutionary improvement.

Before the 2020's a DB (SQL, Object, FTS, Graph, etc.) would be stored on an SSD, NVMe, SSD, etc. 
But now cloud providers have machines that have 512 Gigs of RAM and more, and even terabytes of RAM is available. And RAM is much faster than SSDs. 
And if terabytes if to small for your DB? You can cluster you DB cloud containers and combine several DB servers into one any size you need.

We can still use cheap S3 type storage to dump things. But for HFT, AdTech, Data Science and such: we can and should store in RAM. 

Our old friend REDIS works well, as does SQLite. SQLite works in RAM, or can have temp tables in RAM for materialized views.

Our new friends include Aerospkie, Spark, Clickhouse, Apache Ignite, etc. 

This is a a paradigm shift, and requires learning and internalizing. So not only should your cloud VM's be 512 Gig or RAM or more, your local development machine should also have 128Gig of RAM or more. (Some development workstation examples with 128Gig plus or RAM: iMac Pro, System 76 and Digital Tigers).

## #3: Tools: Gradle.build, Jitpack, Cloud IDE.

Before the '20's, we used to use POM.xml. The improvement is self evident with gradle.build.

Compare the power, here a build.gradle that publishes a jar to Jitpack, so you can use the jar in apps via gradle (or maven). Once published, you can now use your lib anywhere in the JVM ecosystem. It is self evident how  much easier the new way is compared to what we had to deal with publishing with XML to Maven:

```
buildscript {
  repositories {
    maven { url "https://jitpack.io" }
  }
  dependencies {
    classpath 'com.github.jengelman.gradle.plugins:shadow:5.2.0'
  }
}
plugins { id 'com.github.johnrengelman.shadow' version '5.2.0' }

apply plugin: 'com.github.johnrengelman.shadow'
repositories {
	maven { url 'https://jitpack.io' }
    mavenCentral()
}
dependencies { }
archivesBaseName = 'XXX'
shadowJar {
   baseName = 'XXX'
   classifier = '' archiveVersion = ''
}
tasks.build.dependsOn tasks.shadowJar
artifacts { archives shadowJar }
// needs jitpack.yaml in root for java version and gradle for its version
group = 'com.github.jitpack'

```

It is just as easy to publish a jar as it is to publish npm from the NodeJS ecosystem. Also a big win is that it is less likely that you will break the build, as everything including IDE's revolves around the gradle.build.


Aside, before the '20s we started deploying to cloud. Now our IDE can be in the cloud also, eg: CodeAnywhere.


### Example 1: 

Here is an example project folder that includes items we mentioned so far: Scala, gradle.build and SQLite. It is a simple Scala project that uses a Java lib (in the lib folder, but deployed )
 that measures how many records we can insert per second. You can change the code to have SQLite built-in feature to use RAM instead of disk. It leverages a few helper classes that I added to the SNX lib.

- https://github.com/cekvenich/SNX/tree/master/SNX_01


### Next: JAMstack.org

Next few points will touch on something called JAMstack, simplistically it is an  API way of working with (generated) front end, including SPA.

## #4: JAR, not WAR, plus Reactive Streams.

#### A quick history lesson
In ancient times, Java would use containers such as Tomcat via WAR files that contained WEB-INF/libs and such. Then it eveloved into using Trustin Lee's Netty project - used by Twiter, Akka, and more. Netty was an async (NIO) network library, just a jar and did not need WAR or container making it easier to maintain. 

Also in 2010's Reactive programming became popular (I won't explain here what Reactive is, it would take more space, but most of the explanation on WWW are poor) and Reactive Streams were added to Java 9 by Doug Lea. Apache http core has a Java library by Oleg Kalnichevski that leverages the Java 9 reactive streams. 

### Example 2: 

Here is an example Scala project folder that uses Apache http core library v5 that emits a simple GET JSON. It also acts as a simple HTTP Server, so you can write an index.html that uses **fetch()**, we don't use Ajax anymore. There is an HTML page that calls fetch() to GET a JSON response. The example is synchronous, but you can easily make it reactive if you adjust the code a bit. TODO XXXXX

- https://github.com/cekvenich/SNX/tree/master/SNX_02


## #5: Stress/Load testing

Java now comes with a built in HTTP Client. In the past we might have setup jMeter or Grinder, but now writing a test script the uses the built in Java HTTP Client wrapped in executor pool makes it just as easy to script GETs and POSTs. I have a helper class that I use:

XXXXXX

Stress/Load testing is **not optional**. It can be scripted into your CI process to catch any performance regressions. Github has hooks that can transparently call our little Apache http core lib (and  email us the performance results as well as use the Jitpack API as needed). 


## 7 Client-side View Model, Auth and more

## 8 SSR (Server Side Rendering) with Pug

### Like NodeJS's Express

## 9 QUnit

##### Example: Test the API/VM

## 10 Edge (no https)

#### Topology aware client, DNS and Edge processing

## 11 Back pressure

## 12 Hiring


# Bad smells

## A. Hitchen's Razor & bombastic executive adjectives


#### Fake Big Data 


#### 30X faster. MemSQL



#### Impossible to overstate


## B. 'No XML Assholes'

#### Channeling Linus

#### Rod Johnson hints to reduce XML

#### Alternatives: Front-End, Python, Node.js, Go

#### Logging in Java

## C. Interruptions, like Slack

At home, checking work email.

#### Rengnogled 

## Conclusion

Are you an experienced Java tech leader?
If so:

- I listed 12 good particles. Is there a 13th?

- I listed 2 bad practices. Is the a 3rd?

- And most important: is there anything I should remove!

Reach out to me please and help me. vic(at) eml.cc


#### Forced sharding

#### Blue-Green Deployments

#### To master new way you must absorb the tools
